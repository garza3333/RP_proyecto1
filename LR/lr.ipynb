{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurLogisticRegression:\n",
    "    def __init__(self, lr=0.01, num_iter=100000, fit_intercept=True):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "       \n",
    "\n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "\n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def __loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "\n",
    "        # weights initialization\n",
    "        self.w = np.zeros(X.shape[1])\n",
    "\n",
    "        for i in range(self.num_iter):\n",
    "            z = np.dot(X, self.w)\n",
    "            h = self.__sigmoid(z)\n",
    "            gradient = np.dot(X.T, (h-y)) / y.size\n",
    "            #print(gradient.shape, self.w.shape, z.shape,h.shape)\n",
    "            #gradient = (h - y) / y.size\n",
    "            self.w -= self.lr * gradient\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "\n",
    "        return self.__sigmoid(np.dot(X, self.w))\n",
    "\n",
    "    def predict(self, X, threshold):\n",
    "        return self.predict_prob(X) >= threshold\n",
    "    def score(self, y_pred,y_test):\n",
    "        return float(sum(y_pred == y_test)) / float(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI   \n",
       "0            6      148             72             35        0  33.6  \\\n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv\")\n",
    "df.head()\n",
    "\n",
    "#X = np.array([[1,2],[1,3],[1,4],[1,5]])\n",
    "#y = np.array([[0],[0],[1],[1]])\n",
    "#ourRegression=LogisticRegression(alpha=0.01,iterations=10000)\n",
    "\n",
    "#w, J_history = ourRegression.gradient_descent(X, y)\n",
    "\n",
    "#print(\"W encontrado por gradiente descendente: \")\n",
    "#print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']\n",
    "X=df[features]\n",
    "y=df.Outcome\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20860/586271459.py:13: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "model = OurLogisticRegression(lr=0.03, num_iter=100)\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities for test set\n",
    "probs = model.predict_prob(X_test)\n",
    "\n",
    "# predict classes for test set\n",
    "y_pred = model.predict(X_test, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.538961038961039\n"
     ]
    }
   ],
   "source": [
    "#print(y_pred)\n",
    "#print(y_test)\n",
    "print(\"Precisión: \",model.score(y_pred,y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso para uniformar la informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixNotas\n",
      "  Proyecto1Docu Proyecto1 Proyecto2 Proyecto2Docu Examen1  Tarea1  Total\n",
      "0          77.0     100.0     100.0         100.0    53.3    76.0   80.2\n",
      "1                     0.0                            12.6     0.0    2.5\n",
      "2         100.0     100.0      45.0         100.0    49.6   100.0   80.8\n",
      "3                                                             0.0    0.0\n",
      "4         100.0     100.0     100.0         100.0    61.6    66.7   82.1\n",
      "fixNotas\n",
      "   Proyecto1Docu Proyecto1  Proyecto2  Proyecto2Docu  Examen1  Tarea1  Total\n",
      "0          100.0     100.0      100.0           92.3     74.4   100.0  96.00\n",
      "1           69.3      43.0       60.0           84.7     41.0          64.97\n",
      "2          100.0      50.0      100.0          100.0     34.0    53.3  79.64\n",
      "3           30.7      38.0        0.0            0.0     16.7     0.0  11.69\n",
      "4            0.0      20.0        0.0            0.0      9.0    38.7  10.80\n",
      "fixNotas\n",
      "  Proyecto1Docu Proyecto1 Proyecto2 Proyecto2Docu Examen1  Tarea1  Total\n",
      "0          92.0      85.0      70.0         100.0    39.9    81.3  77.12\n",
      "1         100.0      34.0      45.0         100.0    43.8    33.3  58.13\n",
      "2         100.0      40.0      45.0         100.0    37.3     9.3  43.75\n",
      "3         100.0      53.3      95.0         100.0    68.6    20.0  83.63\n",
      "4         100.0      52.0      65.0         100.0    28.8    33.3  74.67\n",
      "fixNotas\n",
      "  Proyecto1Docu Proyecto1 Proyecto2 Proyecto2Docu  Examen1  Tarea1  Total\n",
      "0         100.0     100.0     100.0         100.0     86.5   100.0  94.97\n",
      "1         100.0      98.0     100.0         100.0     53.3   100.0  87.85\n",
      "2          91.7      85.0      70.0          92.3     55.5   100.0  84.43\n",
      "3          91.7      47.5      71.7         100.0     27.3    33.3  67.94\n",
      "4                    14.0                              5.0    80.0  10.86\n",
      "     Proyecto1Docu  Proyecto1  Proyecto2  Proyecto2Docu  Examen1   Tarea1   \n",
      "0           2.8875    11.2500    4.38000       13.12000    7.995  2.85000  \\\n",
      "1           0.0000     0.0000    0.00000        0.00000    1.890  0.00000   \n",
      "2           3.7500    11.2500    1.97100       13.12000    7.440  3.75000   \n",
      "3           0.0000     0.0000    0.00000        0.00000    0.000  0.00000   \n",
      "4           3.7500    11.2500    4.38000       13.12000    9.240  2.50125   \n",
      "..             ...        ...        ...            ...      ...      ...   \n",
      "100         3.7500     6.8625    3.06600       12.10976    8.895  3.75000   \n",
      "101         3.7500    11.2500    3.86754       13.12000    9.945  3.75000   \n",
      "102         3.7500    11.2500    4.38000       13.12000    8.160  3.75000   \n",
      "103         3.7500    11.2500    4.38000       13.12000   10.800  3.75000   \n",
      "104         3.7500     9.4275    4.38000       13.12000    4.740  0.00000   \n",
      "\n",
      "     Total  \n",
      "0    80.20  \n",
      "1     2.50  \n",
      "2    80.80  \n",
      "3     0.00  \n",
      "4    82.10  \n",
      "..     ...  \n",
      "100  84.18  \n",
      "101  87.47  \n",
      "102  86.24  \n",
      "103  87.31  \n",
      "104  69.37  \n",
      "\n",
      "[105 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# datos1 = pd.read_csv('../DataSetGrades/2021-s1.csv')\n",
    "# print(datos1)\n",
    "notas2021s1 = pd.read_csv('../DataSetGrades/2021-s1.csv', sep =';')\n",
    "notas2021s2 = pd.read_csv('../DataSetGrades/2021-s2.csv', sep =';')\n",
    "notas2022s1 = pd.read_csv('../DataSetGrades/2022-s1.csv', sep =';')\n",
    "notas2022s2 = pd.read_csv('../DataSetGrades/2022-s2.csv', sep =';')\n",
    "\n",
    "\n",
    "# Compara los nombres de las columnas\n",
    "#if set(notas2021s2.columns) == set(notas2022s1.columns):\n",
    "#    print(\"Los nombres de las columnas son iguales para ambos archivos\")\n",
    "#else:\n",
    "#    print(\"Los nombres de las columnas son diferentes para ambos archivos\")\n",
    "\n",
    "#notas2021s1.head()\n",
    "#print(notas2021s1)\n",
    "#columnasMantener2022s2 = ['proyecto 1,', 'proyecto 2', 'examen 1', 'tarea 1']\n",
    "columnasMantener2021s1 = ['Proyecto Individual Docu 3.75%', 'Proyecto Individual Funcional 11.25%', 'Proyecto Grupal 1 Funcional 13.12%', 'Proyecto Grupal 1 Docu 4.38%', 'Examen 1 15.0%', 'Tarea 1 3.75%', 'Total: ']\n",
    "columnasMantener2021s2 = ['Proyecto Indiviual Docu 3.75%', 'Proyecto Individual Funcional 11.25%', 'Proyecto Grupal 1 Funcional 13.12%', 'Proyecto Grupal 1 Docu 4.38%', 'Examen 1 15.0%', 'Tarea 1', 'Total: ']\n",
    "columnasMantener2022s1 = ['Proyecto Individual Docu 3.75%', 'Proyecto Individual Funcional 11.25%', 'Proyecto Grupal 1 Funcional 13.12%', 'Proyecto Grupal 1 Docu 4.38%', 'Examen parcial 1 15%', 'Tarea 1 evaluación 3.75%', 'Total: ']\n",
    "columnasMantener2022s2 = ['Proyecto Individual Docu 3.75%', 'Proyecto Individual Funcional 11.25%', 'Proyecto Grupal 1 Func Eval 13.12%', 'Proyecto Grupal 1 Docu Eval 4.38%', 'Examen parcial 1 15%', 'Tarea 1 3.75%', 'Total: ']\n",
    "\n",
    "fixNotas2021s1 = notas2021s1.loc[:, columnasMantener2021s1]\n",
    "fixNotas2021s2 = notas2021s2.loc[:, columnasMantener2021s2]\n",
    "fixNotas2022s1 = notas2022s1.loc[:, columnasMantener2022s1]\n",
    "fixNotas2022s2 = notas2022s2.loc[:, columnasMantener2022s2]\n",
    "\n",
    "\n",
    "nombresNuevos1 = {'Proyecto Individual Docu 3.75%': 'Proyecto1Docu', 'Proyecto Individual Funcional 11.25%': 'Proyecto1', 'Proyecto Grupal 1 Funcional 13.12%':'Proyecto2', 'Proyecto Grupal 1 Docu 4.38%':'Proyecto2Docu', 'Examen 1 15.0%': 'Examen1', 'Tarea 1 3.75%':'Tarea1', 'Total: ':'Total'}\n",
    "fixNotas2021s1 = fixNotas2021s1.rename(columns=nombresNuevos1)\n",
    "nombresNuevos2 = {'Proyecto Indiviual Docu 3.75%': 'Proyecto1Docu', 'Proyecto Individual Funcional 11.25%': 'Proyecto1', 'Proyecto Grupal 1 Funcional 13.12%':'Proyecto2', 'Proyecto Grupal 1 Docu 4.38%':'Proyecto2Docu', 'Examen 1 15.0%': 'Examen1', 'Tarea 1':'Tarea1', 'Total: ':'Total'}\n",
    "fixNotas2021s2 = fixNotas2021s2.rename(columns=nombresNuevos2)\n",
    "nombresNuevos3 = {'Proyecto Individual Docu 3.75%': 'Proyecto1Docu', 'Proyecto Individual Funcional 11.25%': 'Proyecto1', 'Proyecto Grupal 1 Funcional 13.12%':'Proyecto2', 'Proyecto Grupal 1 Docu 4.38%':'Proyecto2Docu', 'Examen parcial 1 15%': 'Examen1', 'Tarea 1 evaluación 3.75%':'Tarea1', 'Total: ':'Total'}\n",
    "fixNotas2022s1 = fixNotas2022s1.rename(columns=nombresNuevos3)\n",
    "nombresNuevos4 = {'Proyecto Individual Docu 3.75%': 'Proyecto1Docu', 'Proyecto Individual Funcional 11.25%': 'Proyecto1', 'Proyecto Grupal 1 Func Eval 13.12%':'Proyecto2', 'Proyecto Grupal 1 Docu Eval 4.38%':'Proyecto2Docu', 'Examen parcial 1 15%': 'Examen1', 'Tarea 1 3.75%':'Tarea1', 'Total: ':'Total'}\n",
    "fixNotas2022s2 = fixNotas2022s2.rename(columns=nombresNuevos4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datos_unificados = pd.concat([fixNotas2021s1, fixNotas2021s2, fixNotas2022s1, fixNotas2022s2], ignore_index=True)\n",
    "datos_unificados = datos_unificados.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "datos_unificados['Proyecto1Docu'] = pd.to_numeric(datos_unificados['Proyecto1Docu'], errors='coerce')\n",
    "datos_unificados['Proyecto1'] = pd.to_numeric(datos_unificados['Proyecto1'], errors='coerce')\n",
    "datos_unificados['Proyecto2'] = pd.to_numeric(datos_unificados['Proyecto2'], errors='coerce')\n",
    "datos_unificados['Examen1'] = pd.to_numeric(datos_unificados['Examen1'], errors='coerce')\n",
    "datos_unificados['Tarea1'] = pd.to_numeric(datos_unificados['Tarea1'], errors='coerce')\n",
    "datos_unificados['Total'] = pd.to_numeric(datos_unificados['Total'], errors='coerce')\n",
    "datos_unificados['Proyecto2Docu'] = pd.to_numeric(datos_unificados['Proyecto2Docu'], errors='coerce')\n",
    "\n",
    "\n",
    "datos_unificados.to_csv('notasUnificadas.csv', index=False)\n",
    "\n",
    "#probs = model.predict_prob(X_test)\n",
    "\n",
    "# predict classes for test set\n",
    "#y_pred = model.predict(X_test, 0.5)\n",
    "#print(\"Precisión: \",model.score(y_pred,y_test))\n",
    "Proyecto1Docu = 3.75\n",
    "Proyecto1 = 11.25\n",
    "Proyecto2Docu = 13.12\n",
    "Proyecto2 = 4.38\n",
    "Examen1 = 15\n",
    "Tarea1 = 3.75\n",
    "Total = 67.5\n",
    "datos_unificados = datos_unificados.fillna(0)\n",
    "datos_unificados['Proyecto1Docu'] = datos_unificados['Proyecto1Docu'].apply(lambda x: x*Proyecto1Docu/100)\n",
    "datos_unificados['Proyecto1'] = datos_unificados['Proyecto1'].apply(lambda x: x*Proyecto1/100)\n",
    "datos_unificados['Proyecto2Docu'] = datos_unificados['Proyecto2Docu'].apply(lambda x: x*Proyecto2Docu/100)\n",
    "datos_unificados['Proyecto2'] = datos_unificados['Proyecto2'].apply(lambda x: x*Proyecto2/100)\n",
    "datos_unificados['Examen1'] = datos_unificados['Examen1'].apply(lambda x: x*Examen1/100)\n",
    "datos_unificados['Tarea1'] = datos_unificados['Tarea1'].apply(lambda x: x*Tarea1/100)\n",
    "\n",
    "datos_unificados.head()\n",
    "#print(datos_unificados)\n",
    "\n",
    "# Guarda los datos modificados en un nuevo archivo CSV\n",
    "#datos.to_csv('archivo_modificado.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando feature engeneering\n",
    "Primero se debe proceder a eliminar todos los datos negativos, en este caso todos loq ue tuvieron 0 en cada asignacion o notuvieron valor alguno dando como nota final un 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilizando la regla del rango intercuartílico\n",
    "Se basa en sacar los intecuartiles de un set de datos encontrados en 75% y el 25% de los datos, ademas es usado especialemente para encontrar outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Proyecto1Docu  Proyecto1  Proyecto2  Proyecto2Docu  Examen1  Tarea1   \n",
      "0             77.0      100.0      100.0          100.0     53.3    76.0  \\\n",
      "1              0.0        0.0        0.0            0.0     12.6     0.0   \n",
      "2            100.0      100.0       45.0          100.0     49.6   100.0   \n",
      "3              0.0        0.0        0.0            0.0      0.0     0.0   \n",
      "4            100.0      100.0      100.0          100.0     61.6    66.7   \n",
      "..             ...        ...        ...            ...      ...     ...   \n",
      "100          100.0       61.0       70.0           92.3     59.3   100.0   \n",
      "101          100.0      100.0       88.3          100.0     66.3   100.0   \n",
      "102          100.0      100.0      100.0          100.0     54.4   100.0   \n",
      "103          100.0      100.0      100.0          100.0     72.0   100.0   \n",
      "104          100.0       83.8      100.0          100.0     31.6     0.0   \n",
      "\n",
      "     Total  \n",
      "0    80.20  \n",
      "1     2.50  \n",
      "2    80.80  \n",
      "3     0.00  \n",
      "4    82.10  \n",
      "..     ...  \n",
      "100  84.18  \n",
      "101  87.47  \n",
      "102  86.24  \n",
      "103  87.31  \n",
      "104  69.37  \n",
      "\n",
      "[105 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calcula la IQR\n",
    "Q1 = datos_unificados.quantile(0.25)\n",
    "Q3 = datos_unificados.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identifica los outliers\n",
    "outliers = ((datos_unificados < (Q1 - 1.5 * IQR)) | (datos_unificados > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "#print(datos_unificados[outliers])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilizando z-score\n",
    "Este se basa principalemente de la desviacion estandar la cual da como un valor que no debe sobre pasar un rango, si lo hace se considera unoutlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "data = datos_unificados.fillna(0)\n",
    "data = datos_unificados.values\n",
    "\n",
    "# Calcula el z-score de cada valor\n",
    "z_scores = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "\n",
    "# Identifica los outliers\n",
    "outliers = (abs(z_scores) > 3).any(axis=1)\n",
    "print(data[outliers])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecucion de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1      2.50\n",
      "21     2.00\n",
      "0     80.20\n",
      "86    87.62\n",
      "37    76.90\n",
      "67    79.32\n",
      "94    23.79\n",
      "64    76.16\n",
      "13    78.60\n",
      "33    91.50\n",
      "2     80.80\n",
      "45    80.09\n",
      "44    97.61\n",
      "90    22.01\n",
      "97    88.04\n",
      "82     0.75\n",
      "60    93.99\n",
      "58    92.61\n",
      "4     82.10\n",
      "55     1.25\n",
      "7     70.70\n",
      "79    66.38\n",
      "10    77.60\n",
      "43     0.00\n",
      "25    69.60\n",
      "26    96.00\n",
      "9     67.60\n",
      "20    76.30\n",
      "74    94.97\n",
      "23    68.30\n",
      "18    80.20\n",
      "77    67.94\n",
      "Name: Total, dtype: float64\n",
      "Precisión:  0.0\n"
     ]
    }
   ],
   "source": [
    "datos_unificados = datos_unificados.fillna(0)\n",
    "result = df['A'].apply(lambda x: x + 1)\n",
    "# Seleccionar todas las columnas excepto la última como x\n",
    "x = datos_unificados.iloc[:, :-1]\n",
    "\n",
    "# Seleccionar la última columna como y\n",
    "y = datos_unificados.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=45)\n",
    "\n",
    "model = OurLogisticRegression(lr=0.001, num_iter=1000)\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities for test set\n",
    "probs = model.predict_prob(X_test)\n",
    "\n",
    "# predict classes for test set\n",
    "y_pred = model.predict(X_test, 0.7)\n",
    "\n",
    "#print(x)\n",
    "#print(y)\n",
    "print(probs)\n",
    "print(y_test)\n",
    "\n",
    "print(\"Precisión: \",model.score(y_pred,y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
